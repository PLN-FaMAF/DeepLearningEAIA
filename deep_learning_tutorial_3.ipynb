{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Express Deep Learning in Python - Part 3\n",
    "\n",
    "## Tensorboard and other cool stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have seen so far how to build our networks and how to train them, but the hard part of Deep Learning radicates many times in finding the *best* architecture and hyperparameters for our task. Sometimes that is more an art than a science, because neural classifiers are opaque: their parameters don't have a clear interpretation. If we can't understand why the neural network is behaving in such a way, how can we improve the results?\n",
    "\n",
    "We want to show you, as the last part of the tutorial, **Tensorboard**. This is a tool that will allow you to run experiments and visualize results in an easy and (hopefully) faster way.\n",
    "\n",
    "[Tensorboard](https://www.tensorflow.org/get_started/summaries_and_tensorboard) has being designed to work with TensoFlow variables directly, but we can still use some basic functionalities from Keras. Let's see a quick example and what type of things it can do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.datasets import mnist\n",
    "\n",
    "from keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will load our dataset and compile our model just as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_classes = 10\n",
    "TRAIN_EXAMPLES = 60000\n",
    "TEST_EXAMPLES = 10000\n",
    "\n",
    "# the data, shuffled and split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# reshape the dataset to convert the examples from 2D matrixes to 1D arrays.\n",
    "x_train = x_train.reshape(60000, 28*28)\n",
    "x_test = x_test.reshape(10000, 28*28)\n",
    "\n",
    "# to make quick runs, select a smaller set of images.\n",
    "train_mask = numpy.random.choice(x_train.shape[0], TRAIN_EXAMPLES, replace=False)\n",
    "x_train = x_train[train_mask, :].astype('float32')\n",
    "y_train = y_train[train_mask]\n",
    "test_mask = numpy.random.choice(x_test.shape[0], TEST_EXAMPLES, replace=False)\n",
    "x_test = x_test[test_mask, :].astype('float32')\n",
    "y_test = y_test[test_mask]\n",
    "\n",
    "# normalize the input\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(784,)))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=keras.optimizers.Adam(),\n",
    "              metrics=['accuracy', 'mae'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will create a **Callback** to store the results in the required format so Tensorboard can graphic them later. This is the only modification we need in order to use Tensorboard. By default, the callback is going to store the loss and metric values, called scalars. You can also log the graph structure of your model and the gradients used during the optimization. However, take into account that the more things you log, the slower your classifier will be.\n",
    "\n",
    "Every time we train the model we need to use a different folder so the results won't collapse with eachother, it's useful to create a counter to identify the runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "EXPERIMENT_COUNTER = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard = TensorBoard(log_dir='./logs/experiment-{}'.format(EXPERIMENT_COUNTER), histogram_freq=0,\n",
    "                          write_graph=False, write_images=False)\n",
    "epochs = 10\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=0,\n",
    "                    validation_data=(x_test, y_test),\n",
    "                    callbacks=[tensorboard])\n",
    "EXPERIMENT_COUNTER += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the model is trained, you need to open a console and run\n",
    "\n",
    "```\n",
    "$ tensorboard --logdir=path/to/log-directory\n",
    "```\n",
    "\n",
    "In this case, the `path/to/log-directory` is the path to the folder logs that you set when defininf the callback. If the command does not fail, go to `http://localhost:6006/` in your browser and you should see the main screen of Tensorboard. If you run this code multiple times, new experiment folders will be created and more results will be available to compare. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:keras]",
   "language": "python",
   "name": "conda-env-keras-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
