{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Express Deep Learning in Python\n",
    "\n",
    "## Tensorboard and other cool stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have seen so far how to build our networks and how to train them, but the hard part of Deep Learning radicated many times in finding the **best** architecture and hyperparameters for our task. Sometimes this is more an art than a science, because neural classifiers are opaque: their parameters don't have a clear interpretation. If we can't understand why the neural network is behaving in such a way, how can we improve the results?\n",
    "\n",
    "We want to show you, as the last part of the tutorial, Tensorboard. This is a tool that will allow you to run experiments and compare results in an easy and (hopefully) faster way.\n",
    "\n",
    "Tensorboard has being designed to work with TensoFlow variables directly, but we can still use some basic functionalities from Keras. Let's see a quick example and what type of things it can do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.datasets import mnist\n",
    "\n",
    "from keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will load our dataset and compile our model just as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "EXPERIMENT_COUNTER = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 10\n",
    "TRAIN_EXAMPLES = 6000#0\n",
    "TEST_EXAMPLES = 1000#0\n",
    "\n",
    "# the data, shuffled and split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# reshape the dataset to convert the examples from 2D matrixes to 1D arrays.\n",
    "x_train = x_train.reshape(60000, 28*28)\n",
    "x_test = x_test.reshape(10000, 28*28)\n",
    "\n",
    "# to make quick runs, select a smaller set of images.\n",
    "x_train = x_train[:TRAIN_EXAMPLES].astype('float32')\n",
    "x_test = x_train[:TEST_EXAMPLES].astype('float32')\n",
    "\n",
    "# normalize the input\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train[:TRAIN_EXAMPLES], num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test[:TEST_EXAMPLES], num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(784,)))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=keras.optimizers.Adam(),\n",
    "              metrics=['accuracy', 'mae'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will create a ยบ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_11 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 407,050\n",
      "Trainable params: 407,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 6000 samples, validate on 1000 samples\n",
      "Epoch 1/10\n",
      "6000/6000 [==============================] - 0s - loss: 0.7407 - acc: 0.7930 - mean_absolute_error: 0.0757 - val_loss: 6.6534 - val_acc: 0.0950 - val_mean_absolute_error: 0.1807\n",
      "Epoch 2/10\n",
      "6000/6000 [==============================] - 0s - loss: 0.2853 - acc: 0.9227 - mean_absolute_error: 0.0310 - val_loss: 7.2862 - val_acc: 0.0940 - val_mean_absolute_error: 0.1809\n",
      "Epoch 3/10\n",
      "6000/6000 [==============================] - 0s - loss: 0.2099 - acc: 0.9440 - mean_absolute_error: 0.0239 - val_loss: 7.7744 - val_acc: 0.0920 - val_mean_absolute_error: 0.1812\n",
      "Epoch 4/10\n",
      "6000/6000 [==============================] - 0s - loss: 0.1634 - acc: 0.9585 - mean_absolute_error: 0.0195 - val_loss: 8.2502 - val_acc: 0.0920 - val_mean_absolute_error: 0.1811\n",
      "Epoch 5/10\n",
      "6000/6000 [==============================] - 0s - loss: 0.1310 - acc: 0.9662 - mean_absolute_error: 0.0163 - val_loss: 8.6950 - val_acc: 0.0920 - val_mean_absolute_error: 0.1812\n",
      "Epoch 6/10\n",
      "6000/6000 [==============================] - 0s - loss: 0.1012 - acc: 0.9767 - mean_absolute_error: 0.0131 - val_loss: 9.0298 - val_acc: 0.0920 - val_mean_absolute_error: 0.1811\n",
      "Epoch 7/10\n",
      "6000/6000 [==============================] - 0s - loss: 0.0818 - acc: 0.9825 - mean_absolute_error: 0.0111 - val_loss: 9.4082 - val_acc: 0.0890 - val_mean_absolute_error: 0.1815\n",
      "Epoch 8/10\n",
      "6000/6000 [==============================] - 0s - loss: 0.0646 - acc: 0.9872 - mean_absolute_error: 0.0092 - val_loss: 9.7752 - val_acc: 0.0920 - val_mean_absolute_error: 0.1814\n",
      "Epoch 9/10\n",
      "6000/6000 [==============================] - 0s - loss: 0.0520 - acc: 0.9907 - mean_absolute_error: 0.0076 - val_loss: 9.9857 - val_acc: 0.0920 - val_mean_absolute_error: 0.1814\n",
      "Epoch 10/10\n",
      "6000/6000 [==============================] - 0s - loss: 0.0415 - acc: 0.9938 - mean_absolute_error: 0.0063 - val_loss: 10.2908 - val_acc: 0.0940 - val_mean_absolute_error: 0.1814\n",
      "Test loss: 10.2908330383\n",
      "Test accuracy: 0.094\n"
     ]
    }
   ],
   "source": [
    "tensorboard = TensorBoard(log_dir='./logs/sample-{}'.format(EXPERIMENT_COUNTER), histogram_freq=0, batch_size=32,\n",
    "                          write_graph=True, write_images=False)\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test),\n",
    "                    callbacks=[tensorboard])\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:keras]",
   "language": "python",
   "name": "conda-env-keras-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
