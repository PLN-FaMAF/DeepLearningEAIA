{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Express Deep Learning in Python\n",
    "\n",
    "## How fast can you build a MLP?\n",
    "\n",
    "In this tutorial we aim to give you some notions on how Deep Learning algorithms are implemented and the key points to use them and not get burned in the process. We will center on how to translate the theory of neural networks easily into efficient code with as little effort as possible. We won't teach you how to implement the complex algorithms involved, but rather how to ensemble the available parts to get the classification pipeline you want. You don't need to be an expert in machine learning or deep learning to understand this content, but some prior background is required. Also, we count on you knowing how to program in Python and how to use Jupyter Notebooks. \n",
    "\n",
    "In this first part we will see how to implement the basic components of a MultiLayer Perceptron (MLP) classifier, most commonly known as Neural Network. We will be working with the Keras: a very simple library for deep learning.\n",
    "\n",
    "At this point, you may know how machine learning in general is applied and have some intuitions about how deep learning works, and more importantly, why it works. Now it's time to make some experiments, and for that you need to be as quick and flexible as possible. Keras is an idea tool for prototyping and doing your first approximations to a Machine Learning problem. On the one hand, Keras is integrated with two very powerfull backends that support GPU computations, Tensorflow and Theano. On the other hand, it has a level of abstraction high enough to be simple to understand and easy to use. For example, it uses a very similar interface to the sklearn library that you have seen before, with fit and predict methods.\n",
    "\n",
    "Now let's get to work with an example:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 - The libraries\n",
    "Firts let's check we have installed everything we need for this tutorial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 - The dataset\n",
    "\n",
    "For this quick tutorial we will use the (very popular) [MNIST dataset](http://yann.lecun.com/exdb/mnist/). This is a dataset of 70K images of handwritten digits. Our task is to recognize which digits is displayed in the image: a classification problem. You have seen in previous courses how to train and evaluate a classifier, so we wont talk in further details about supervised learning.\n",
    "\n",
    "The input to the MLP classifier are going to be images of 28x28 pixels represented as matrixes. The output will be one of ten classes (0 to 9), representing the predicted number written in the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 10\n",
    "TRAIN_EXAMPLES = 6000#0\n",
    "TEST_EXAMPLES = 1000#0\n",
    "\n",
    "# the data, shuffled and split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# reshape the dataset to convert the examples from 2D matrixes to 1D arrays.\n",
    "x_train = x_train.reshape(60000, 28*28)\n",
    "x_test = x_test.reshape(10000, 28*28)\n",
    "\n",
    "# to make quick runs, select a smaller set of images.\n",
    "x_train = x_train[:TRAIN_EXAMPLES].astype('float32')\n",
    "x_test = x_train[:TEST_EXAMPLES].astype('float32')\n",
    "\n",
    "# normalize the input\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train[:TRAIN_EXAMPLES], num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test[:TEST_EXAMPLES], num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 - The model\n",
    "\n",
    "The concept of Deep Learning is very broad, but the core of it is the use of classifiers with multiple hidden layer of neurons, or smaller classifiers. We all know the classical image of the simplest possible possible deep model: a neural netowrk with a single hidden layer. \n",
    "\n",
    "![Neural Network](files/NeuralNetwork.png \"Title\")\n",
    "\n",
    "credits http://www.extremetech.com/wp-content/uploads/2015/07/NeuralNetwork.png\n",
    "\n",
    "In theory, this model can represent any function ***TODO*** add a citation here. We will see how to implement this network in Keras, and during the second part of this tutorial how to add more features to create a deep and powerful classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, Deep Learning models are concatenations of Layers. This is represented in Keras with the Sequential model. We create the Sequential instance as an \"empty carcass\" and then we fill it with different layers. \n",
    "\n",
    "The most basic type of Layer is the Dense layer, where each neuron in the input is connected to each neuron in the following layer, like we can see in the image above. Internally, a Dense layer has two variables: a matrix of weights and a vector of bias, but you beauty of Keras is that you don't need to worry about that. All the variables will be correctly created, initialized, trained and possibly regularized for you.\n",
    "\n",
    "Each layer needs to know or be able to calculate al least three things:\n",
    "\n",
    "* The size of the input: the number of neurons in the incoming layer. For the first layer this corresponds to the size of each example in our dataset. The next layers can calculate their input size using the output of the previous layer, so we generally don't need to tell them this.\n",
    "* The type of activation: this is the function that is applied to the output of each neuron. Will talk in detail about this later.\n",
    "* The size of the output: the number of neurons in the next layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# Input to hidden layer\n",
    "model.add(Dense(512, activation='relu', input_shape=(784,)))\n",
    "# Hidden to output layer\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have successfully build a Neural Network! We can print a description of our architecture using the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 407,050\n",
      "Trainable params: 407,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compiling a model in Keras\n",
    "\n",
    "A very appealing aspect of Deep Learning frameworks is that they solve the implementation of complex algorithms such as Backpropagation. For those with some numerical optimization notions, minimization algorithms often involve the calculation of first defivatives. Neural Networks are huge functions full of non-linearities, and differentiating them is a... let's say nightmare. For this reason, models need to be \"compiled\". In this stage, the backend builds complex computational graphs, and we don't have to worry about derivatives or gradients.\n",
    "\n",
    "In Keras, a model can be compiled with the method .compile(). The method takes two parameters: loss and optimizer. The loss is the function that calculates how much error we have in each prediction example, and there are a lot of implemented alternatives ready to use. We will talk more about this, for now we use the standard categorical crossentropy. As you can see, we can simply pass a string with the name of the function and Keras will find the implementation for us. We could, as well, pass a custom function as parameter.\n",
    "\n",
    "The optimizer is the algorithm to minimize the value of the loss function. Again, Keras has many optimizers available. The basic one is the Stochastic Gradient Descent.\n",
    "\n",
    "\n",
    "***TODO*** add metrics\n",
    "\n",
    "***TODO*** explain what is the fit method (same as sklearn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 407,050\n",
      "Trainable params: 407,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 6000 samples, validate on 1000 samples\n",
      "Epoch 1/10\n",
      "6000/6000 [==============================] - 0s - loss: 0.7069 - acc: 0.8130 - val_loss: 6.7218 - val_acc: 0.0950\n",
      "Epoch 2/10\n",
      "6000/6000 [==============================] - 0s - loss: 0.2730 - acc: 0.9252 - val_loss: 7.3553 - val_acc: 0.0940\n",
      "Epoch 3/10\n",
      "6000/6000 [==============================] - 0s - loss: 0.2102 - acc: 0.9443 - val_loss: 7.8410 - val_acc: 0.0950\n",
      "Epoch 4/10\n",
      "6000/6000 [==============================] - 0s - loss: 0.1597 - acc: 0.9567 - val_loss: 8.3432 - val_acc: 0.0940\n",
      "Epoch 5/10\n",
      "6000/6000 [==============================] - 0s - loss: 0.1256 - acc: 0.9697 - val_loss: 8.6390 - val_acc: 0.0930\n",
      "Epoch 6/10\n",
      "6000/6000 [==============================] - 0s - loss: 0.1002 - acc: 0.9762 - val_loss: 9.1287 - val_acc: 0.0930\n",
      "Epoch 7/10\n",
      "6000/6000 [==============================] - 0s - loss: 0.0792 - acc: 0.9822 - val_loss: 9.4369 - val_acc: 0.0900\n",
      "Epoch 8/10\n",
      "6000/6000 [==============================] - 0s - loss: 0.0624 - acc: 0.9870 - val_loss: 9.7261 - val_acc: 0.0920\n",
      "Epoch 9/10\n",
      "6000/6000 [==============================] - 0s - loss: 0.0515 - acc: 0.9893 - val_loss: 10.0837 - val_acc: 0.0940\n",
      "Epoch 10/10\n",
      "6000/6000 [==============================] - 0s - loss: 0.0407 - acc: 0.9942 - val_loss: 10.3408 - val_acc: 0.0940\n",
      "Test loss: 10.340819458\n",
      "Test accuracy: 0.094\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=keras.optimizers.Adam(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test),\n",
    "                    callbacks=[tensorboard])\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'categorical_crossentropy'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"410pt\" viewBox=\"0.00 0.00 171.00 410.00\" width=\"171pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 406)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" points=\"-4,4 -4,-406 167,-406 167,4 -4,4\" stroke=\"none\"/>\n",
       "<!-- 139827565628720 -->\n",
       "<g class=\"node\" id=\"node1\"><title>139827565628720</title>\n",
       "<polygon fill=\"none\" points=\"0,-365.5 0,-401.5 163,-401.5 163,-365.5 0,-365.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"81.5\" y=\"-379.8\">dense_1_input: InputLayer</text>\n",
       "</g>\n",
       "<!-- 139827565628944 -->\n",
       "<g class=\"node\" id=\"node2\"><title>139827565628944</title>\n",
       "<polygon fill=\"none\" points=\"30.5,-292.5 30.5,-328.5 132.5,-328.5 132.5,-292.5 30.5,-292.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"81.5\" y=\"-306.8\">dense_1: Dense</text>\n",
       "</g>\n",
       "<!-- 139827565628720&#45;&gt;139827565628944 -->\n",
       "<g class=\"edge\" id=\"edge1\"><title>139827565628720-&gt;139827565628944</title>\n",
       "<path d=\"M81.5,-365.313C81.5,-357.289 81.5,-347.547 81.5,-338.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"85.0001,-338.529 81.5,-328.529 78.0001,-338.529 85.0001,-338.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139827565629392 -->\n",
       "<g class=\"node\" id=\"node3\"><title>139827565629392</title>\n",
       "<polygon fill=\"none\" points=\"19,-219.5 19,-255.5 144,-255.5 144,-219.5 19,-219.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"81.5\" y=\"-233.8\">dropout_1: Dropout</text>\n",
       "</g>\n",
       "<!-- 139827565628944&#45;&gt;139827565629392 -->\n",
       "<g class=\"edge\" id=\"edge2\"><title>139827565628944-&gt;139827565629392</title>\n",
       "<path d=\"M81.5,-292.313C81.5,-284.289 81.5,-274.547 81.5,-265.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"85.0001,-265.529 81.5,-255.529 78.0001,-265.529 85.0001,-265.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139827565628608 -->\n",
       "<g class=\"node\" id=\"node4\"><title>139827565628608</title>\n",
       "<polygon fill=\"none\" points=\"30.5,-146.5 30.5,-182.5 132.5,-182.5 132.5,-146.5 30.5,-146.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"81.5\" y=\"-160.8\">dense_2: Dense</text>\n",
       "</g>\n",
       "<!-- 139827565629392&#45;&gt;139827565628608 -->\n",
       "<g class=\"edge\" id=\"edge3\"><title>139827565629392-&gt;139827565628608</title>\n",
       "<path d=\"M81.5,-219.313C81.5,-211.289 81.5,-201.547 81.5,-192.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"85.0001,-192.529 81.5,-182.529 78.0001,-192.529 85.0001,-192.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139827565709632 -->\n",
       "<g class=\"node\" id=\"node5\"><title>139827565709632</title>\n",
       "<polygon fill=\"none\" points=\"19,-73.5 19,-109.5 144,-109.5 144,-73.5 19,-73.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"81.5\" y=\"-87.8\">dropout_2: Dropout</text>\n",
       "</g>\n",
       "<!-- 139827565628608&#45;&gt;139827565709632 -->\n",
       "<g class=\"edge\" id=\"edge4\"><title>139827565628608-&gt;139827565709632</title>\n",
       "<path d=\"M81.5,-146.313C81.5,-138.289 81.5,-128.547 81.5,-119.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"85.0001,-119.529 81.5,-109.529 78.0001,-119.529 85.0001,-119.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139827377187752 -->\n",
       "<g class=\"node\" id=\"node6\"><title>139827377187752</title>\n",
       "<polygon fill=\"none\" points=\"30.5,-0.5 30.5,-36.5 132.5,-36.5 132.5,-0.5 30.5,-0.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"81.5\" y=\"-14.8\">dense_3: Dense</text>\n",
       "</g>\n",
       "<!-- 139827565709632&#45;&gt;139827377187752 -->\n",
       "<g class=\"edge\" id=\"edge5\"><title>139827565709632-&gt;139827377187752</title>\n",
       "<path d=\"M81.5,-73.3129C81.5,-65.2895 81.5,-55.5475 81.5,-46.5691\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"85.0001,-46.5288 81.5,-36.5288 78.0001,-46.5289 85.0001,-46.5288\" stroke=\"black\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28, 1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:keras]",
   "language": "python",
   "name": "conda-env-keras-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
